# Would You Rather Let the World Burn or Be a Side Character?
When someone gets convinced that advanced AI is coming soon and might end the world, you’d expect them to focus on how we can all work together to stop it. But often, the opposite happens. The thinking turns inward, and the priority shifts from "how do we avoid a catastrophe?" to "what's my part going to be in this historical moment?"

We’ve all heard the "well, if someone's gonna build it, may as well be me" line.
As Sam Altman put it,
> "I think AI will probably, like most likely, sort of lead to the end the world, but in the meantime there will be great companies created with serious machine learning."

Or as Elon Musk put it,
> "I sort of came to the realization that it’s happening whether I do it or not. So you can either be a spectator or a participant. I’d rather be a participant."

I think Elon's quote is importantly different from Sam's, in that it's more about being a side character than it is about craving the money/power associated with building AGI.

Everyone wants to be a part of the AGI story. If the world is watching [Pantheon](https://en.wikipedia.org/wiki/Pantheon_(TV_series)) play out in slow motion, it's only natural to want to be part of the show. When I really self-reflect, there's something kinda cool about being the villain with wild dreams of an AGI future, who's steadfastly resolved to build the machine god, as opposed to a random extra that you only see for a single scene.

Anthropic, for example, has a super freaking awesome story going on. They split off from OpenAI because they thought it was too reckless. Instead, they’re racing to develop AGI before OpenAI, then planning to use their AGI to solve alignment and save the world from the bad guys. This is a pretty epic role in the show; much better than the coffee shop role AND the evil villain.

### A less egregious instance of this
If you really care about being part of the action, you might do things that slightly harm AI safety overall, to steer the ship in your favor. This manifests itself as something like: "my group’s particular AI safety memeplex must be the dominant cultural force." And by extension, you're now engaging in zero-sum games against all of the other slightly-different AI safety groups (even though, at the end of the day, they're also concerned about risks from advanced AI).

### Who I strive to be
In the grand story of AGI, I aspire to be like the janitor from the movie "[Perfect Days](https://en.wikipedia.org/wiki/Perfect_Days)."

> Hirayama works as a public toilet cleaner in Tokyo‘s upscale Shibuya district, across town from his modest home in a middle-class neighbourhood east of the Sumida River. He repeats his structured, repetitive routine each day, starting at dawn. He dedicates his free time to his passion for music cassettes, which he listens to in his van to and from work, and to his books, which he reads every night before going to sleep. His dreams are shown in flickery impressionistic sequences at the end of every day. Hirayama is also fond of trees and spends time gardening and photographing trees. He eats a sandwich every day in the shade under trees in the grounds of a shrine, and takes film photos of their branches and leaves and the ‘Komorebi’ (木漏れ日) – sunlight filtered by the leaves. His pride in his work is apparent by its thoroughness and precision.

Hirayama is the quiet janitor who keeps the bathrooms clean, takes care of repairs, and works with a certain quiet, calm dignity, making the city a functional and clean place.

This quiet dignity is a virtue I think is especially respectable in the age of AGI, and is remarkably different from the “centerpice of a grand narrative” frame that I feel when I watch Pantheon, or read these AI company CEO quotes.

### On the other hand,
There are times when it’s important to take the spotlight. The Indian independence movement wouldn’t have succeeded without Gandhi as its face.

I think the difference is why you’re stepping forward. Gandhi didn’t lead because he wanted to be the main character in the history books.

The problem is that when it feels like you’re watching a show, it’s easy to start taking story-like actions. I think when I catch myself wanting to be part of the narrative, it’s a sign I’m not actually feeling the weight of the moment. If you really felt what AGI means—for your parents, children, and grandchildren—you wouldn’t care about your part in the story. You’d just be focused on making it go well.
